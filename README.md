# MSCS 634 – Lab 3: Wine Dataset Clustering

## Purpose
This lab explores clustering using the Wine dataset from scikit-learn.  
It applies **K-Means** and **K-Medoids (PAM)** with k = 3 and compares their performance using:

- Silhouette Score
- Adjusted Rand Index (ARI)

---

## Files
- `MSCS_634_Lab_3_Wine_Clustering.ipynb`  
  Jupyter notebook containing data preparation, clustering, evaluation metrics, visualizations, and analysis.

---

## Key Insights
- The notebook prints Silhouette Score and ARI for both K-Means and K-Medoids.  
  Compare these values to determine:
  - Which method produced better cluster separation
  - Which method aligned more closely with the true class labels

- **K-Medoids** is generally more robust to outliers because medoids are actual data points.
- **K-Means** is computationally faster and works well for roughly spherical clusters.

---

## Run Instructions
1. Open the notebook in **Jupyter Notebook** or **JupyterLab**.
2. Run all cells in order.
3. The notebook installs `scikit-learn-extra` (for `KMedoids`) if not already installed.

---

## Challenges / Design Decisions
- `KMedoids` is provided by `scikit-learn-extra`; a setup cell ensures installation.
- PCA (2 components) is used for visualization to project standardized features into 2D space.
- Feature scaling (StandardScaler) is applied before clustering to prevent scale dominance.

---

Generated by **Mahesh Gaire**  
MSCS 634 – Machine Learning
